---
title: "Global Temperature"
format: html
editor: visual
---

## How to predict climate change with little knowledge about it

This is an experiment I decided to do a while ago. When I was in my undergraduate studies of geography, I learnt some things about climate geography, but I am no expert in the field. I went on to specialize in economic geography, and obtained a master's degree in Quantitative Economics.

For my master's thesis, I learnt how to perform time series analysis in R. I started to wonder: The time series package I used was written by economists. My degree was in economics. But in principle, statistics is an universal field. Could I predict the climate using a model we normally use to predict very different types of data?

Of course, I can. If the result makes sense is another question. Anything I create in a few hours at home with a basic knowledge about climate and a model that will contain very little information and only replicate very few aspects of the real world will obviously never be as good as a model developed by experts who include considerably more details.

Considering this, I was surprised how well one of my models performed. And I learnt a lot about forecasts on the way. So, let's look at what an extremely simple model can and can not tell us about the global climate.

## Forecasting a time series

In order to predict the future, it is obvious we first need to know things about the present. We know global climate change is happening, and one of its main aspects is an increase in the average global temperature. I therefore started out with a model that aims to predict the future global temperature based on current and past temperature observations.

So, it got some data on the global temperature from NASA: https://climate.nasa.gov/vital-signs/global-temperature/

Simply click on the Download Data button to get the data. Thank you to NASA for that. The data can be saved locally and read into R with this command:

```{r}
Temp <- read.table("Global Temperature.txt")
```

The data is now stored in a variable called 'Temp'.

Also, we're going to get some R packages we'll need to build the model and make the forecast.

```{r}
library(tidyverse)
library(fable)
```

Now, I need to turn the data into a format called 'tsibble'. This is a format which contains information on how the data is structured. The data contains the global temperature by year. In the NASA data, the year is saved in a column named V1, so I name this column as index when saving the data as tsibble.

```{r}
Temptsibble <- as_tsibble(Temp, index = V1)
```

Tsibble is a format specifically useful when working with time series. A time series is a type of data where there is a time dimension in the data - data that has, for example, been measured daily, weekly, or, as here, yearly. Each observation has a specific time assigned to it. In this case, there is one observation per year.

In the next step, I'll take a look at the data. I'll rename the columns and look at the first observations.

```{r}
colnames(Temptsibble) <- c("Year", "Temperature", "Smoothed_Temperature") 
Temptsibble(head)
```

It can be seen that the data starts in 1880. The temperature has been measured as deviation from the global long-term average temperature 1951 to 1980. It is visible that in the early years (the data starts at 1880), it was colder than this average. It could change relatively strongly from year to year, so NASA used a Smoothing algorithm to reduce the variance. The result of applying this algorithm to the data is seen in the column 'Smoothed_Temperature'.

The fable package has a convenient way to create a graph from that data quickly:

```{r}
autoplot(Temptsibble,.vars =Temperature)
```

Changing .vars to 'Smoothed_Temperature' allows to look at the smoothed temperature values instead. Later, I will add proper labels and make the graph more pretty, but for now, as a quick overview, this is enough. It can be seen that the data goes from 1880 to around 2020, that the temperature can vary from year to year quite strongly, but also, that there is a strong increasing trend since around 1980.

Now, I'll build a model and create a forecast based on this model.

```{r}
# Create a model.
fit <- Temptsibble %>% model(ARIMA(Temperature))
# Create a forecast from the model.
forecast <- fit %>% forecast(h=50) 
# Plot the model.
autoplot(forecast, Temptsibble)
```

That was quick. I love R.

This model predicts an increase of the temperature in the years from 2020 to 2070 (the prediction is the blue line in the graph). Its prediction has large confidence intervals (the blue and light blue areas around the prediction).

Confidence intervals are extremely important in predictions. A prediction is unlikely to be entirely accurate. A confidence interval can be read as 'with a probability of x%, the future value will lie in this interval'. The future values will lie with 80% probability in the blue confidence interval and with 95% probability in the light blue interval.

Step by step, what I did to create this forecast was:

1.  Creating an ARIMA model with the temperature data and saving this model in the variable 'fit'
2.  Creating a forecast ten years into the future (h=10) from the model.
3.  Plotting this forecast. More precisely, the autoplot-function above first plots the data and then appends the forecast. It is possible to plot only the forecast by removing 'Temptsibble' from the autoplot function.

Now, I'll take a closer look at the model.

```{r}
report(fit)
```

As seen above, this model is called 'ARIMA', that means 'Autoregressive integrated moving average'.

An autoregressive model aims to predict the current temperature based on previous temperature values. It is called auto-regressive because the variable to be explained (here: temperature) is explained through its previous values. I will not go into too many details here, but it is worth noting such models can have relatively complex dynamics even though they only contain a single input variable.

So this model predicts that the temperature will rise, but the possibility that it may stay constant is within the confidence interval. It does not really predict climate change accurately, but its confidence intervals, despite being fairly large, exclude the possibility that the temperature may return to the level of 1960 or even 2000. For such a model, which only makes predictions based on past observations of the temperature, it would be impossible to predict an increase in temperature if climate change had not occurred yet in the past. But since the average global temperature has been increasing for a few decades now, the model picks up that trend and predicts a slow increase as most likely future path.

## Bringing CO2 into the picture

Because this model only uses temperature data, it can not take the future effect of greenhouse gasses into account. It only contains data on past temperature increases caused by greenhouse gasses, but does not have any data on the greenhouse gasses themselves - only on the effects they had on the temperature so far. But of course, they will continue to have an effect.

This effect, in reality, is complex. There are various greenhouse gasses, some of which have stronger effects than others. For my model, I will focus on carbon dioxide. It is the greenhouse gas which is the main driver of global climate change because fossil-fuel burning industries release it into the atmosphere in large amounts.

I downloaded data on past carbon dioxide levels in the atmosphere from the following page:

https://scrippsco2.ucsd.edu/data/atmospheric_co2/icecore_merged_products.html

I used the [merged_ice_core_yearly.csv](https://scrippsco2.ucsd.edu/assets/data/atmospheric/merged_ice_core_mlo_spo/merged_ice_core_yearly.csv) - file from this webpage. I modified the data to be able to use it for my prediction. I assigned duplicates to different years (because the data combines sources, it sometimes gives more than one value for a year) or removed them, and removed some observations for which the temperature data I used so far does not contain any values.

```{r}
Merged_data <- read.csv("merged_ice_core_yearly.csv", header = TRUE,sep = ",", skip = 46, row.names = NULL)
colnames(Merged_data) = c("year", "CO2")
Merged_data$year<- as.integer(Merged_data$year)
Merged_data[74,1] <- 1885
Merged_data[80,1] <- 1898
Merged_data[82,1] <- 1900
Merged_data[83,1]<-1903
Merged_data[87,1] <- 1913
Merged_data[92,1] <- 1924
Merged_data[121,1] <- 1956
#Remove the remaining duplicates:
data <- Merged_data[!duplicated(Merged_data$year),]
#Cut data: The temperature data only starts at 1880, and only goes to 2020.
CO2data <- data[73:175,]
# Because of missing CO2 observations until 1885, cut the Temperature data.
Temptsibble <- Temptsibble[6:141,]
```

```{r}
#This code expands the CO2 dataset to include all years and temperatures for them and include NA's where no CO2 values are in the data.
a <- expand.grid(year = 1885:2020)
b <- merge(CO2data, a, all = TRUE)
b$CO2 <- as.numeric(b$CO2)
CO2tsibble <- as_tsibble(b, index = year)
CO2tsibble$Temperature = Temptsibble$Temperature
```

The combined dataset now contains three columns: Year, CO2 and Temperature. Plotting Temperature and CO2 besides each other, the relation between them becomes visible:

```{r}
autoplot(CO2tsibble, vars(CO2tsibble$CO2, CO2tsibble$Temperature))
```

But the plots also show some differences: Yearly temperatures are subjected to large fluctuations while the CO2 levels rose steadily since 1960. For the years before 1960 and especially the very early years, the line is incomplete because for some years, there was no data on the CO2 levels available.

I filled in the gaps for the missing observations. I did that using a ARIMA model again - just like these models can be used to forecast, they can also be used to predict past values with interpolate function.

```{r}
# This code replaces the NA values with predicted values
CO2tsibblefull <-  CO2tsibble %>%
# Fit ARIMA model to the data containing missing values
model(ARIMA(CO2)) %>%
# Estimate the CO2 values for all periods
interpolate(CO2tsibble)

CO2tsibblefull%>%autoplot(.vars = CO2)


```

It is clearly visible that the carbon dioxide level in the atmosphere rose during the 20th century, and especially quickly from 1960 on. The carbon dioxide data uses the unit parts per million, so ,300' means that from one million particles in the atmosphere, 300 were carbon dioxide. This was the case around 1910. By 2020, it were more than 400. In this year, the average global temperature was 1 degree Celsius above the average temperature.

To see how temperature and the carbon dioxide levels are connected, they can be plotted. The graph below shows the temperature on the y-axis and the carbon dioxide level on the x-axis.

```{r}
Co2_climate_1 <- bind_cols(CO2tsibblefull, Temptsibble$Temperature)
colnames(Co2_climate_1) <- c("Year", "CO2", "Temperature")
ggplot(Co2_climate_1, aes(x = CO2, y = Temperature)) +
    geom_point()
```

Such relationships can be captured using a linear regression. A linear regression is one of the most widely used statistical methods. It creates a model which aims to represent the connection in a linear formula. One can imagine it as an attempt to draw a straight line through the datapoints above.

```{r}
my_graph <- ggplot(Co2_climate_1, aes(x = CO2, y = Temperature)) +
    geom_point() +
    stat_smooth(method = "lm",
                formula = 'y~x',
        col = "#C42126",
        se=FALSE,
        size = 1)
my_graph
```

It is clearly visible from the data how the two are related. There are many different ways to visualize this relationship. For example, the picture below, a bubble-chart, displays year and temperature on the x and y axis and the amount of carbon dioxide in the atmosphere as size of the depicted circles.

```{r}
 ggplot(Co2_climate_1, aes(Year, Temperature)) + geom_point(aes(size = CO2), shape = 21)
```

## Predicting future CO2 levels

To build a prediction of the future average global temperature based on the future CO2-levels, an assumptions about the future CO2 levels is necessary. There are several ways to construct valid assumptions:

1.  CO2 is emitted by industries. One could try to estimate how much carbon dioxide future industries would release, based on their current emission level, their predicted growth or shrinkage, reforms for them to use renewable energies and other aspects. The disadvantage is that such a model would require a large amount of information.
2.  Another way would be to predict the future CO2-levels, based on present observations. The same ARIMA model used above for the first prediction of the global temperature can also be used to predict future carbon dioxide levels.
3.  Finally, different scenarios can be simulated. For example, it is possible to make a prediction for the case that CO2 emissions would suddenly stop.

In the next step, CO2 levels will be predicted using an ARIMA model.

```{r}
# Create an ARIMA model
fit_Co2_for_prognosis <- Co2_climate_1 %>%
  model(ARIMA(CO2))

# Create a forecast of future Co2 levels based on the model:
Forecast_Co2_for_prognosis <- fit_Co2_for_prognosis %>% forecast(h=50) 
autoplot(Forecast_Co2_for_prognosis,Co2_climate_1)

```

As can be seen, the model predicts rising CO2 levels with a high confidence (the blue areas, the confidence intervals, are much smaller than they were for the first attempt at temperature prediction).

## Predicting global average temperatures for CO2 levels

Let us take the mean annual value of CO2 in the atmosphere predicted by the model and use it to predict the mean global average temperature.

```{r}
# Take the year and mean Co2 value from the Co2 forecast:
Future <- as.data.frame(bind_cols(Forecast_Co2_for_prognosis$Year, Forecast_Co2_for_prognosis$.mean))
#Rename its columns and turn it into a tsibble:
colnames(Future) <- c("Year", "CO2")
Future = as_tsibble(Future, index= Year)

# Create the model:
fit_temperature_CO2 <-Co2_climate_1 %>%
  model(ARIMA(Temperature ~ CO2))
#report(fit_temperature_CO2)

# Create and show the forecast:
forecast(fit_temperature_CO2, new_data = Future) %>%autoplot(Co2_climate_1)

# Save the forecast as forecast 1:
#Forecast_1 = forecast(fit_temperature_CO2, Co2_climate_1, new_data = Future )
```

As can be seen, the confidence interval is more narrow now. The model predicts an increase with higher certainty than the first model. It also predicts a faster increase:

The first model did not predict the temperature to rise above 1.5 degrees within the next 50 years.

This second model already predicts the average global temperature to rise above the 1.5 degree-line in 2040.

There is still some variation, but it appears to cover the extent of cyclic global average temperature changes, so for such a simple model, this is probably nearly as good as it can get. There are more complex ARIMA models better suited for the prediction of cyclic values, like seasonal models, but I was surprised by how precise this relatively simple model is.

For comparsion, this is a prediction published by UCAR, an association of universities and colleges for atmospheric research.

![](Global-surface-temperature_6July2022.png.webp)

You can find it here: https://scied.ucar.edu/learning-zone/climate-change-impacts/predictions-future-global-climate

It looks so familiar it made me wonder if the creators of these predictions used ARIMA models, too. But their predicted temperatures are not directly comparable: As mentioned above, the NASA data gives the temperature relative to the long-term average of the temperatures measured from 1951 to 1980.

The UCAR graph, on the other hand, refers to the IPCC which uses the temperature from 1850 to 1900 as baseline. Therefore, the temperature is already above zero from 1950 in their graph. But the patterns predicted by the models look very similar. My model predicts that the average global temperature will lie above 1.5 degrees from 2040, and above 2 after 2060. UCAR calculates five different scenarios, of which the medium to high and the medium scenario are closest to the predictions of my model. The highest scenario predicts an increase of nearly a whole degree from 2040 to 2060 while the two lowest scenarios predict nearly no increase or even a decrease during this time.

As mentioned above, the model I showed is build on the assumption that CO2 levels will develop like they did in the past, up until 2020 (any ARIMA model continues existing trends, it can not predict structural breaks). But this will not necessarily be the case. UCAR has created various scenarios, and this is possible with our model as well.

So now, we will take a look at how to create a prediction for another scenario. Assume, for example, that from 2021 on, net yearly emissions were zero (all CO2 emitted would be absorbed so the CO2 level in the atmosphere would remain constant.

To create a future with this assumption is straightforward: Look up the value from 2020 (412 ppm) in the dataset and repeat it several times, using the same years as for the forecast above.

```{r}
# Repeat the value from 2020 50 times.
Future2 <- as.data.frame( cbind(Forecast_Co2_for_prognosis$Year, rep(412, times=50 )))
colnames(Future2) <- c("Year", "CO2")
Future2 = as_tsibble(Future2, index= Year)

#Fit the model
fit_temperature_CO2_2 <-Co2_climate_1 %>%
  model(ARIMA(Temperature ~ CO2))
report(fit_temperature_CO2_2)

#Create and show the forecast.
forecast(fit_temperature_CO2_2, new_data = Future2) %>%autoplot(Co2_climate_1)
```

This model does not respect real physical dynamics. It captures a relation between CO2-emissions and temperature, but predicts global warming to stop immediately as soon as the amount of carbon dioxide remains constant. In reality, the effect is relatively quick, but there is a certain lag.

More severe, the model can also not capture 'tipping points'. It only captures the relationship between carbon dioxide and global warming that has already impacted the data. Future issues like the aspect that the ocean becomes acid and will therefore absorb less carbon dioxide can not be anticipated. To predict such dynamics, a more complete model with data on absorption capacity of the ocean and yearly emissions would be needed (this model only uses data about carbon dioxide in the atmosphere). Likewise with tipping points like the amazon rainforest, Albedo and so on (use Albedo as example).

Untersuchen, was jeweils als Nullpunkt genommen wurde.

Finally, we can create a pessimistic scenario. Say CO2 emissions were rising

This is not working yet.

```{r}
Year = Forecast_Co2_for_prognosis$Year
a = 412
emptyvector = c()
for (i in Year)
  {print(i)
  a = a*(5/100*a)
  emptyvector = c(emptyvector, a)}

Future3 <- as.data.frame( cbind(Forecast_Co2_for_prognosis$Year, emptyvector))
colnames(Future3) <- c("Year", "CO2")
Future3 = as_tsibble(Future2, index= Year)

fit_temperature_CO2_2 <-Co2_climate_1 %>%
  model(ARIMA(Temperature ~ CO2))
report(fit_temperature_CO2_2)

#Hier wird der Forecast erstellt und angezeigt.
forecast(fit_temperature_CO2_2, new_data = Future3) %>%autoplot(Co2_climate_1)
```
